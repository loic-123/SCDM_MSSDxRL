{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSSD x RL: Full Experiment Pipeline\n",
    "\n",
    "This notebook runs the **complete MSSD (Multi-Scale Sequential Shift Detector)** pipeline end-to-end:\n",
    "\n",
    "1. **Install dependencies** and verify GPU availability\n",
    "2. **Train RL agents** (Tabular Q-learning for CliffWalking, DQN for CartPole)\n",
    "3. **Collect reference observations** from the trained agents under nominal conditions\n",
    "4. **Run the unit tests** to validate all components\n",
    "5. **Run a smoke test** (quick 2-trial sweep) to verify the pipeline works end-to-end\n",
    "6. **Run full experiment sweeps** (50 trials x 3 shift types x 3 severities per environment)\n",
    "7. **Generate figures and LaTeX tables** for the report\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "MSSD wraps a deployed RL agent with a **runtime monitor** that diagnoses *which aspect* of the observation distribution has shifted:\n",
    "\n",
    "| Probe | What it detects | Statistic |\n",
    "|-------|----------------|----------|\n",
    "| **Body** | Mean/variance shift | MMD (d>4) or max-KS (d<=4) |\n",
    "| **Tail** | Rare dangerous states | CVaR_0.95 difference |\n",
    "| **Structure** | Correlation breakdown | Frobenius norm of correlation diff |\n",
    "\n",
    "Each probe's test statistic is converted to an **e-value** via block-bootstrap permutation, then accumulated in a **product martingale**. An alarm fires when the combined log-wealth exceeds `log(1/alpha)`, and the probe with the highest log-wealth provides the **diagnosis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "Make sure you are running this notebook from the project root directory, or adjust the paths below.\n",
    "\n",
    "If you have a **conda environment** with GPU-enabled PyTorch (e.g., `torch_5070`), activate it before launching Jupyter:\n",
    "```bash\n",
    "conda activate torch_5070\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the project root (adjust if needed)\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent if Path(os.getcwd()).name == \"notebooks\" else Path(os.getcwd())\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package in editable mode (run once)\n",
    "!pip install -e . -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability\n",
    "\n",
    "DQN training for CartPole benefits from GPU acceleration. The `device: \"auto\"` setting in `configs/defaults.yaml` will automatically use CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"No GPU detected - training will use CPU (slower for DQN, fine for Tabular Q).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output directories\n",
    "\n",
    "All artifacts (trained agents, reference data, experiment results, figures) are stored under `artifacts/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p artifacts/agents/cliffwalking artifacts/agents/cartpole\n",
    "!mkdir -p artifacts/reference\n",
    "!mkdir -p artifacts/results\n",
    "!mkdir -p artifacts/figures artifacts/tables artifacts/logs\n",
    "print(\"Output directories created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Train RL Agents\n",
    "\n",
    "We train two agents:\n",
    "\n",
    "### 1a. Tabular Q-learning for CliffWalking-v1\n",
    "\n",
    "- **Environment**: `CliffWalking-v1` wrapped with `CliffWalkingContinuousObs` to produce 3D observations `(row, col, cliff_distance)` instead of a single integer state.\n",
    "- **Algorithm**: Tabular Q-learning with epsilon-greedy exploration.\n",
    "- **Episodes**: 5,000 training episodes.\n",
    "- **Output**: Q-table saved as `.npy` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/train_agent.py \\\n",
    "    --config configs/envs/cliffwalking.yaml \\\n",
    "    --output artifacts/agents/cliffwalking/q_table.npy \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. DQN for CartPole-v1\n",
    "\n",
    "- **Environment**: `CartPole-v1` with 4D native observations `(x, x_dot, theta, theta_dot)`.\n",
    "- **Algorithm**: Deep Q-Network with experience replay and target network.\n",
    "- **Episodes**: 500 training episodes.\n",
    "- **Device**: Automatically uses GPU if available (set via `--device auto`).\n",
    "- **Output**: PyTorch checkpoint saved as `.pt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/train_agent.py \\\n",
    "    --config configs/envs/cartpole.yaml \\\n",
    "    --output artifacts/agents/cartpole/dqn_checkpoint.pt \\\n",
    "    --seed 42 \\\n",
    "    --device auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Collect Reference Observations\n",
    "\n",
    "We deploy each trained agent in the **nominal (unshifted)** environment and collect observations. These serve as the **reference distribution** against which the MSSD monitor will compare incoming data during deployment.\n",
    "\n",
    "By default, we collect observations from **100 episodes** per environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. CliffWalking reference observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/collect_reference.py \\\n",
    "    --config configs/envs/cliffwalking.yaml \\\n",
    "    --agent artifacts/agents/cliffwalking/q_table.npy \\\n",
    "    --output artifacts/reference/cliffwalking_ref.npz \\\n",
    "    --n-episodes 100 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. CartPole reference observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/collect_reference.py \\\n",
    "    --config configs/envs/cartpole.yaml \\\n",
    "    --agent artifacts/agents/cartpole/dqn_checkpoint.pt \\\n",
    "    --output artifacts/reference/cartpole_ref.npz \\\n",
    "    --n-episodes 100 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect reference data\n",
    "\n",
    "Let's take a quick look at the reference observation shapes to make sure everything is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for env_name in [\"cliffwalking\", \"cartpole\"]:\n",
    "    ref_path = f\"artifacts/reference/{env_name}_ref.npz\"\n",
    "    data = np.load(ref_path)\n",
    "    obs = data[\"observations\"]\n",
    "    print(f\"{env_name}: {obs.shape[0]} observations, {obs.shape[1]}D\")\n",
    "    print(f\"  Mean: {obs.mean(axis=0).round(3)}\")\n",
    "    print(f\"  Std:  {obs.std(axis=0).round(3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Run Unit Tests\n",
    "\n",
    "Before running experiments, let's verify that all components (probes, martingale, metrics, wrappers, shifts) work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pytest tests/unit/ -v --tb=short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 37 unit tests should pass. If any fail, fix the underlying issue before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Smoke Test (Quick Pipeline Validation)\n",
    "\n",
    "Run a **minimal 2-trial sweep** with only body shifts to verify the entire pipeline works end-to-end before committing to the full experiment.\n",
    "\n",
    "This uses `configs/experiments/quick_smoke.yaml`, which overrides defaults for speed:\n",
    "- Only 2 trials (instead of 50)\n",
    "- Only 20 permutations (instead of 200)\n",
    "- Only 200 monitoring steps (instead of 2,000)\n",
    "- Only body shifts (instead of all 3 types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Smoke test on CliffWalking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_sweep.py \\\n",
    "    --config configs/experiments/quick_smoke.yaml \\\n",
    "    --agent artifacts/agents/cliffwalking/q_table.npy \\\n",
    "    --reference artifacts/reference/cliffwalking_ref.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Smoke test on CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_sweep.py \\\n",
    "    --config configs/experiments/quick_smoke.yaml \\\n",
    "    --agent artifacts/agents/cartpole/dqn_checkpoint.pt \\\n",
    "    --reference artifacts/reference/cartpole_ref.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the smoke tests complete without errors, the pipeline is ready for the full experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Run a Single Trial (Optional)\n",
    "\n",
    "You can run individual trials for debugging or closer inspection. This is useful to understand what happens step-by-step.\n",
    "\n",
    "**Parameters**:\n",
    "- `--shift-type`: one of `body`, `tail`, `structure`, or `none`\n",
    "- `--severity`: shift magnitude (higher = stronger shift)\n",
    "- `--trial-id`: integer identifier for this trial\n",
    "- `--seed`: random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: run a single body-shift trial on CliffWalking\n",
    "!python scripts/run_experiment.py \\\n",
    "    --config configs/envs/cliffwalking.yaml \\\n",
    "    --defaults configs/defaults.yaml \\\n",
    "    --agent artifacts/agents/cliffwalking/q_table.npy \\\n",
    "    --reference artifacts/reference/cliffwalking_ref.npz \\\n",
    "    --shift-type body \\\n",
    "    --severity 0.6 \\\n",
    "    --trial-id 0 \\\n",
    "    --seed 1000 \\\n",
    "    --output artifacts/results/single_trial_cliff_body.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: run a single tail-shift trial on CartPole\n",
    "!python scripts/run_experiment.py \\\n",
    "    --config configs/envs/cartpole.yaml \\\n",
    "    --defaults configs/defaults.yaml \\\n",
    "    --agent artifacts/agents/cartpole/dqn_checkpoint.pt \\\n",
    "    --reference artifacts/reference/cartpole_ref.npz \\\n",
    "    --shift-type tail \\\n",
    "    --severity 1.5 \\\n",
    "    --trial-id 0 \\\n",
    "    --seed 2000 \\\n",
    "    --output artifacts/results/single_trial_cartpole_tail.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the result\n",
    "import numpy as np\n",
    "\n",
    "result = dict(np.load(\"artifacts/results/single_trial_cliff_body.npz\", allow_pickle=True))\n",
    "print(\"Single trial result:\")\n",
    "for k, v in result.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Full Experiment Sweeps\n",
    "\n",
    "Now we run the **complete experiments** required for the paper. Each sweep runs:\n",
    "\n",
    "- **50 trials** per condition\n",
    "- **3 shift types**: body, tail, structure\n",
    "- **3 severity levels** per shift type (defined in the env config)\n",
    "- **50 null (no-shift) trials** for false alarm rate estimation\n",
    "- **Total per environment**: 50 x 3 x 3 + 50 = **500 trials**\n",
    "\n",
    "The sweep runs with **4 parallel workers** by default.\n",
    "\n",
    "> **Note**: Full sweeps can take a significant amount of time depending on your hardware. The CliffWalking sweep is faster (tabular agent); the CartPole sweep is heavier (DQN inference on every step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. CliffWalking full sweep\n",
    "\n",
    "Shift types and severities (from `configs/envs/cliffwalking.yaml`):\n",
    "- **Body** (coordinate offset): severities `[0.3, 0.6, 1.0]`\n",
    "- **Tail** (hazard state injection): severities `[1.0, 2.0, 3.0]`\n",
    "- **Structure** (feature decorrelation): severities `[0.5, 1.0, 2.0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_sweep.py \\\n",
    "    --config configs/experiments/sweep_cliffwalking.yaml \\\n",
    "    --agent artifacts/agents/cliffwalking/q_table.npy \\\n",
    "    --reference artifacts/reference/cliffwalking_ref.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. CartPole full sweep\n",
    "\n",
    "Shift types and severities (from `configs/envs/cartpole.yaml`):\n",
    "- **Body** (pole mass drift): severities `[0.1, 0.3, 0.5]`\n",
    "- **Tail** (extreme-angle injection): severities `[1.0, 1.5, 2.0]`\n",
    "- **Structure** (x-theta correlation broken): severities `[0.3, 0.6, 1.0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_sweep.py \\\n",
    "    --config configs/experiments/sweep_cartpole.yaml \\\n",
    "    --agent artifacts/agents/cartpole/dqn_checkpoint.pt \\\n",
    "    --reference artifacts/reference/cartpole_ref.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Generate Figures\n",
    "\n",
    "Once the sweeps are complete, generate the paper figures:\n",
    "\n",
    "- **Orthogonality heatmap** (3x3 matrix): shows which probe fires for each shift type. A diagonal-dominant heatmap confirms that MSSD correctly diagnoses the shift source.\n",
    "- **ADD comparison bar chart**: compares Average Detection Delay between MSSD and the global MMD baseline.\n",
    "- **Log-wealth trajectory plots**: shows how the product martingale accumulates evidence over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Figures from CliffWalking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/generate_figures.py \\\n",
    "    --results-dir artifacts/results/sweep_cliffwalking \\\n",
    "    --output-dir artifacts/figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Figures from CartPole results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/generate_figures.py \\\n",
    "    --results-dir artifacts/results/sweep_cartpole \\\n",
    "    --output-dir artifacts/figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display generated figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "figures_dir = Path(\"artifacts/figures\")\n",
    "for fig_path in sorted(figures_dir.glob(\"*.png\")):\n",
    "    print(f\"\\n--- {fig_path.name} ---\")\n",
    "    display(Image(filename=str(fig_path), width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Generate LaTeX Tables\n",
    "\n",
    "Generate publication-ready LaTeX tables summarizing the results:\n",
    "- Average Detection Delay (ADD) for MSSD vs. baseline\n",
    "- Probe discrimination accuracy\n",
    "- False alarm rate (FAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tables from CliffWalking results\n",
    "!python scripts/generate_tables.py \\\n",
    "    --results-dir artifacts/results/sweep_cliffwalking \\\n",
    "    --output-dir artifacts/tables\n",
    "\n",
    "# Generate tables from CartPole results\n",
    "!python scripts/generate_tables.py \\\n",
    "    --results-dir artifacts/results/sweep_cartpole \\\n",
    "    --output-dir artifacts/tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated LaTeX table\n",
    "from pathlib import Path\n",
    "\n",
    "for tex_path in sorted(Path(\"artifacts/tables\").glob(\"*.tex\")):\n",
    "    print(f\"\\n=== {tex_path.name} ===\")\n",
    "    print(tex_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Quick Results Summary (In-Notebook Analysis)\n",
    "\n",
    "For a quick look at the results directly in the notebook, we can load and analyze them using the built-in evaluation module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from mssd.evaluation.metrics import TrialResult, compute_add, compute_far, compute_discrimination_accuracy\n",
    "\n",
    "def load_results(results_dir):\n",
    "    \"\"\"Load all .npz result files into TrialResult objects.\"\"\"\n",
    "    results = []\n",
    "    for npz_path in Path(results_dir).rglob(\"*.npz\"):\n",
    "        data = dict(np.load(npz_path, allow_pickle=True))\n",
    "        alarm_step = int(data[\"mssd_alarm_step\"])\n",
    "        baseline_step = int(data[\"baseline_alarm_step\"])\n",
    "        results.append(TrialResult(\n",
    "            env_name=str(data[\"env_name\"]),\n",
    "            shift_type=str(data[\"shift_type\"]),\n",
    "            severity=float(data[\"severity\"]),\n",
    "            trial_id=int(data[\"trial_id\"]),\n",
    "            seed=int(data[\"seed\"]),\n",
    "            mssd_alarm_fired=bool(data[\"mssd_alarm_fired\"]),\n",
    "            mssd_alarm_step=alarm_step if alarm_step >= 0 else None,\n",
    "            mssd_diagnosed_probe=str(data[\"mssd_diagnosed_probe\"]) if str(data[\"mssd_diagnosed_probe\"]) != \"none\" else None,\n",
    "            mssd_log_wealth={},\n",
    "            baseline_alarm_fired=bool(data[\"baseline_alarm_fired\"]),\n",
    "            baseline_alarm_step=baseline_step if baseline_step >= 0 else None,\n",
    "            shift_injection_step=int(data[\"shift_injection_step\"]),\n",
    "            total_steps=int(data[\"total_steps\"]),\n",
    "        ))\n",
    "    return results\n",
    "\n",
    "\n",
    "for env in [\"sweep_cliffwalking\", \"sweep_cartpole\"]:\n",
    "    results_dir = f\"artifacts/results/{env}\"\n",
    "    if not Path(results_dir).exists():\n",
    "        print(f\"No results found for {env} - run the sweep first.\")\n",
    "        continue\n",
    "    \n",
    "    results = load_results(results_dir)\n",
    "    if not results:\n",
    "        print(f\"No results found in {results_dir}\")\n",
    "        continue\n",
    "    \n",
    "    shift_results = [r for r in results if r.shift_type != \"none\"]\n",
    "    null_results = [r for r in results if r.shift_type == \"none\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {env.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total trials: {len(results)} ({len(shift_results)} shifted, {len(null_results)} null)\")\n",
    "    \n",
    "    # Detection rate\n",
    "    if shift_results:\n",
    "        detected = sum(1 for r in shift_results if r.mssd_alarm_fired)\n",
    "        print(f\"Detection rate: {detected}/{len(shift_results)} = {detected/len(shift_results):.1%}\")\n",
    "        \n",
    "        # ADD\n",
    "        add = compute_add(shift_results)\n",
    "        print(f\"Average Detection Delay (MSSD): {add:.1f} steps\")\n",
    "    \n",
    "    # FAR\n",
    "    if null_results:\n",
    "        far = compute_far(null_results)\n",
    "        print(f\"False Alarm Rate: {far:.3f} (target: < 0.05)\")\n",
    "    \n",
    "    # Discrimination accuracy per shift type\n",
    "    if shift_results:\n",
    "        for shift_type in [\"body\", \"tail\", \"structure\"]:\n",
    "            typed = [r for r in shift_results if r.shift_type == shift_type]\n",
    "            if typed:\n",
    "                acc = compute_discrimination_accuracy(typed, shift_type)\n",
    "                print(f\"  {shift_type} discrimination accuracy: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Expected outcomes\n",
    "\n",
    "If everything works correctly, you should see:\n",
    "\n",
    "1. **Orthogonality**: The 3x3 heatmap should be **diagonal-dominant**, meaning each probe primarily fires for its corresponding shift type (body probe detects body shifts, tail probe detects tail shifts, structure probe detects structure shifts).\n",
    "\n",
    "2. **Low false alarm rate**: FAR should be below the significance level alpha = 0.05.\n",
    "\n",
    "3. **Competitive detection delay**: MSSD should achieve ADD comparable to or better than the global MMD baseline, while additionally providing a **diagnosis** of the shift type.\n",
    "\n",
    "4. **Severity monotonicity**: Higher severity shifts should be detected faster (lower ADD).\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "- **Agent training fails**: Check that gymnasium is installed and the env name is correct (`CliffWalking-v1`, `CartPole-v1`).\n",
    "- **GPU not detected**: Ensure your conda env has CUDA-enabled PyTorch. Run `torch.cuda.is_available()` to check.\n",
    "- **Sweep takes too long**: Reduce `n_trials` in the sweep config, or increase `parallel_workers`.\n",
    "- **Tests fail**: Run `pytest tests/unit/ -v` and fix any failures before proceeding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}